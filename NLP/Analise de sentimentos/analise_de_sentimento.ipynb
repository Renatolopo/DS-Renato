{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1d151a68831448000e09cfc499a6de9a24b6912dae8debe2df70808284a908ce"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "A ideia desse algoritmo é classificar textos em portugues como positivo, negativo ou neutro usando aprendizado de máquina supervisionado\n",
    "\n",
    "a base de dados usadas para treinar o modelo está disponiveil a seguir:\n",
    "[Teets_MG.csv](https://www.kaggle.com/leandrodoze/tweets-from-mgbr)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import string \n",
    "import os\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/renato/Documentos/Datasets//Tweets_Mg.csv')"
   ]
  },
  {
   "source": [
    "A base contem alguns tweets  classificados como positivo, negativo e neutro que sera usada  para treinar o modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Text Classificacao\n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...        Neutro\n",
       "1  � @ Governador Valadares, Minas Gerais https:/...        Neutro\n",
       "2  �� @ Governador Valadares, Minas Gerais https:...        Neutro\n",
       "3                        ��� https://t.co/BnDsO34qK0        Neutro\n",
       "4  ��� PSOL vai questionar aumento de vereadores ...      Negativo"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Classificacao</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n      <td>Neutro</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n      <td>Neutro</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n      <td>Neutro</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>��� https://t.co/BnDsO34qK0</td>\n      <td>Neutro</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n      <td>Negativo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "# arrumando a base de dados\n",
    "rm_df = [x for x in list(df.columns) if x not in ['Text','Classificacao']]\n",
    "df = df.drop(columns=rm_df)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Text', 'Polaridade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Positivo    27994\n",
       "Negativo    27211\n",
       "Neutro       2453\n",
       "Name: Polaridade, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "df_concat['Polaridade'].value_counts()\n"
   ]
  },
  {
   "source": [
    "Criando o modelo usando naive bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "tweets = df[\"Text\"].values\n",
    "classes = df[\"Polaridade\"].values\n",
    "classes"
   ]
  },
  {
   "source": [
    "Agora, vamos treinar o modelo usando a abordagem Bag of Words e o algoritmo Naive Bayes Multinomial \n",
    " - Bag of Words, na prática, cria um vetor com cada uma das palavras do texto completo da base, depois, calcula a frequência em que essas palavras ocorrem em uma data sentença, para então classificar/treinar o modelo\n",
    "- Exemplo HIPOTÉTICO de três sentenças vetorizadas \"por palavra\" e classificadas baseada na frequência de suas palavras:\n",
    " {0,3,2,0,0,1,0,0,0,1, Positivo}\n",
    " {0,0,1,0,0,1,0,1,0,0, Negativo}\n",
    " {0,1,1,0,0,1,0,0,0,0, Neutro}\n",
    " - Olhando para esses vetores, meu palpite é que as palavras nas posições 2 e 3 são as com maior peso na determinação de a que classe pertence cada uma das três sentenças avaliadas\n",
    " - A função fit_transform faz exatamente esse processo: ajusta o modelo, aprende o vocabulário, e transforma os dados de treinamento em feature vectors, a.k.a. vetor com frequêcia das palavras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Usando Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Qual é o melhor jeito de aumentar a renda no Brasil? - Neutro\nLegalizar o jogo do bicho - Neutro\nEu pensei que seria um aniversário feliz. Tá sendo não :( - Neutro\n"
     ]
    }
   ],
   "source": [
    "# testando modelo com alguns tweets retirados do meu feed\n",
    "testes = [\"Qual é o melhor jeito de aumentar a renda no Brasil?\", \"Legalizar o jogo do bicho\", \"Eu pensei que seria um aniversário feliz. Tá sendo não :(\"]\n",
    "\n",
    "freq_testes = vectorizer.transform(testes)\n",
    "predict = modelo.predict(freq_testes)\n",
    "\n",
    "for i in range(len(testes)):\n",
    "    print(f\"{testes[i]} - {predict[i]}\")"
   ]
  },
  {
   "source": [
    "usando validação cruzada para medir a acuracia do modelo\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8831564824978656"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "source": [
    "### Testando analise de sentimento com random forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = RandomForestClassifier()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.889132821075741"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "source": [
    "### usando TF-IDF ao inves do CountVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "y = df['Polaridade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "punctuations = string.punctuation\n",
    "def spacy_tokenizer(sentence):\n",
    "    sentence = sentence.strip().lower()\n",
    "    mytokens = nlp(sentence)\n",
    "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n",
    "    mytokens = [word for word in  mytokens if word not in pt_spacy_stopwords and word not in punctuations]\n",
    "\n",
    "    return mytokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "pt_spacy_stopwords = spacy.lang.pt.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, _, y, _ = train_test_split(X, y, test_size=0.90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(81, 485)"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "X_tfidf =tfidf_vectorizer.fit_transform(X)\n",
    "X_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "resultados = cross_val_predict(classifier, X_train, y_train, cv = 10)\n",
    "metrics.accuracy_score(y_train, resultados)"
   ]
  }
 ]
}